# üìö RUNBOOK DE OPERA√á√ïES - HARVEY BACKEND

> **Guia completo para opera√ß√£o, monitoramento e troubleshooting do Harvey Backend**

## üö® RESPOSTA A INCIDENTES

### SEV-1: Respostas com Alucina√ß√£o / Factualmente Incorretas

**üîç Diagn√≥stico:**
1. **Identifique o run_id** no log de auditoria:
   ```bash
   kubectl logs -n production deployment/harvey-backend | grep "run_id"
   ```

2. **Analise o relat√≥rio de faithfulness**:
   ```bash
   psql -h $DB_HOST -U $DB_USER -d $DB_NAME -c "
   SELECT run_id, faithfulness_report, sources_used, agent_trace 
   FROM run_audit 
   WHERE run_id = 'UUID_AQUI';"
   ```

3. **Verifique qualidade do contexto RAG**:
   ```bash
   # Acesse o Qdrant para verificar os documentos retornados
   curl -X GET "http://qdrant:6333/collections/legal_docs/points/search" \
     -H "Content-Type: application/json" \
     -d '{"vector": [...], "limit": 10}'
   ```

**‚ö° A√ß√£o Imediata:**
1. **Ative o modo "apenas logs"** para o agente problem√°tico:
   ```bash
   kubectl patch configmap harvey-config -n production -p '{"data":{"AGENT_MODE":"log_only"}}'
   kubectl rollout restart deployment/harvey-backend -n production
   ```

2. **Remova documento mal indexado** (se identificado):
   ```bash
   curl -X DELETE "http://qdrant:6333/collections/legal_docs/points/POINT_ID"
   ```

**‚úÖ Resolu√ß√£o:**
1. **Adicione ao golden dataset**:
   ```bash
   echo "run_id,expected_output,actual_output,issue_type" >> tests/golden_dataset.csv
   echo "UUID_AQUI,OUTPUT_ESPERADO,OUTPUT_ATUAL,hallucination" >> tests/golden_dataset.csv
   ```

2. **Ajuste o prompt do agente**:
   - Edite `app/agents/document_writer.py`
   - Adicione restri√ß√µes mais espec√≠ficas
   - Teste com `pytest tests/test_prompts.py`

3. **Verifique configura√ß√£o do reranker**:
   ```python
   # app/core/rag.py
   reranker_config = {
       "model": "cross-encoder/ms-marco-MiniLM-L-6-v2",
       "top_k": 5,  # Reduza se necess√°rio
       "score_threshold": 0.7  # Aumente para maior qualidade
   }
   ```

---

### SEV-2: API com Lat√™ncia Alta (p95 > 5s)

**üîç Diagn√≥stico:**
1. **Verifique m√©tricas no Grafana**:
   - Acesse `http://grafana.exemplo.com:3000`
   - Dashboard: "Harvey Backend - Performance"
   - M√©tricas: `harvey_api_req_rate`, `harvey_llm_latency_seconds`

2. **Identifique gargalos**:
   ```bash
   # Logs de performance
   kubectl logs -n production deployment/harvey-backend | grep "PERFORMANCE"
   
   # M√©tricas de CPU/Memory
   kubectl top pods -n production
   ```

3. **An√°lise de traces**:
   ```bash
   # Logs do LangGraph
   kubectl logs -n production deployment/harvey-backend | grep "langgraph"
   ```

**‚ö° A√ß√£o Imediata:**
1. **Scale horizontal**:
   ```bash
   kubectl scale deployment harvey-backend --replicas=5 -n production
   ```

2. **Ative fallback de LLM**:
   ```bash
   kubectl patch configmap harvey-config -n production -p '{"data":{"LLM_FALLBACK_ENABLED":"true"}}'
   ```

3. **Ajuste timeout temporariamente**:
   ```bash
   kubectl patch configmap harvey-config -n production -p '{"data":{"API_TIMEOUT":"30"}}'
   ```

**‚úÖ Resolu√ß√£o:**
1. **Otimize prompts**:
   - Reduza tamanho dos prompts
   - Simplifique instru√ß√µes
   - Teste com `pytest tests/test_performance.py`

2. **Otimize RAG**:
   ```python
   # app/core/rag.py
   rag_config = {
       "chunk_size": 1000,  # Reduza para chunks menores
       "chunk_overlap": 200,
       "top_k": 3,  # Reduza n√∫mero de documentos
       "embedding_cache_ttl": 3600  # Cache embeddings
   }
   ```

3. **Configure cache Redis**:
   ```python
   # app/core/cache.py
   cache_config = {
       "ttl": 3600,  # 1 hora
       "max_size": 1000,  # M√°ximo de entradas
       "compression": True  # Compress√£o de dados
   }
   ```

---

### SEV-3: Falha na Auditoria ou Compliance

**üîç Diagn√≥stico:**
1. **Verifique integridade dos hashes**:
   ```sql
   SELECT run_id, input_hash, output_hash, 
          CASE WHEN input_hash IS NULL THEN 'MISSING HASH' ELSE 'OK' END as status
   FROM run_audit 
   WHERE created_at >= NOW() - INTERVAL '1 hour';
   ```

2. **Verifique detec√ß√£o de PII**:
   ```sql
   SELECT run_id, pii_report->>'pii_detected' as pii_detected,
          pii_report->>'pii_types' as pii_types
   FROM run_audit 
   WHERE pii_report->>'pii_detected' = 'true';
   ```

3. **Verifique pol√≠ticas de seguran√ßa**:
   ```bash
   kubectl logs -n production deployment/harvey-backend | grep "POLICY_VIOLATION"
   ```

**‚ö° A√ß√£o Imediata:**
1. **Pare processamento se necess√°rio**:
   ```bash
   kubectl patch configmap harvey-config -n production -p '{"data":{"AUDIT_REQUIRED":"true"}}'
   ```

2. **Ative modo strict de PII**:
   ```bash
   kubectl patch configmap harvey-config -n production -p '{"data":{"PII_STRICT_MODE":"true"}}'
   ```

**‚úÖ Resolu√ß√£o:**
1. **Reprocesse execu√ß√µes sem auditoria**:
   ```python
   # scripts/reprocess_audit.py
   from app.core.audit import build_and_save_audit_record
   
   # Busca runs sem auditoria
   missing_audits = await db.fetch_all(
       "SELECT run_id FROM runs WHERE run_id NOT IN (SELECT run_id FROM run_audit)"
   )
   
   for run in missing_audits:
       # Reprocessa auditoria
       await build_and_save_audit_record(run.run_id)
   ```

---

## üîç MONITORAMENTO E ALERTAS

### M√©tricas Cr√≠ticas

**1. Disponibilidade da API**
```promql
# Uptime da API
up{job="harvey-backend"} * 100

# Taxa de erro
rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) * 100
```

**2. Performance**
```promql
# Lat√™ncia P95
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))

# Throughput
rate(http_requests_total[5m])
```

**3. Recursos**
```promql
# CPU Usage
rate(container_cpu_usage_seconds_total[5m]) * 100

# Memory Usage
container_memory_working_set_bytes / container_spec_memory_limit_bytes * 100
```

**4. Neg√≥cio**
```promql
# Documentos gerados por hora
rate(documents_generated_total[1h])

# Taxa de feedback positivo
rate(feedback_positive_total[1h]) / rate(feedback_total[1h]) * 100
```

### Alertas no Prometheus

```yaml
# alerts/harvey-backend.yml
groups:
  - name: harvey-backend
    rules:
      - alert: HarveyBackendDown
        expr: up{job="harvey-backend"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Harvey Backend est√° fora do ar"
          description: "A API do Harvey Backend n√£o est√° respondendo"

      - alert: HarveyHighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Alta lat√™ncia no Harvey Backend"
          description: "P95 de lat√™ncia est√° acima de 5s: {{ $value }}s"

      - alert: HarveyHighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Alta taxa de erro no Harvey Backend"
          description: "Taxa de erro est√° acima de 5%: {{ $value }}%"
```

---

## üõ†Ô∏è PROCEDIMENTOS DE MANUTEN√á√ÉO

### Deploy de Nova Vers√£o

**1. Prepara√ß√£o**
```bash
# Backup da base de dados
pg_dump -h $DB_HOST -U $DB_USER $DB_NAME > backup_$(date +%Y%m%d_%H%M%S).sql

# Verificar health dos servi√ßos
kubectl get pods -n production
kubectl get svc -n production
```

**2. Deploy**
```bash
# Deploy com Helm
helm upgrade harvey-production ./helm/harvey \
  --set image.tag=v1.2.3 \
  --namespace production \
  --wait \
  --timeout=600s

# Verificar rollout
kubectl rollout status deployment/harvey-backend -n production
```

**3. Verifica√ß√£o**
```bash
# Smoke tests
curl -f https://harvey-api.exemplo.com/health
curl -f https://harvey-api.exemplo.com/metrics

# Verificar logs
kubectl logs -n production deployment/harvey-backend --tail=100
```

**4. Rollback (se necess√°rio)**
```bash
# Rollback para vers√£o anterior
helm rollback harvey-production -n production

# Verificar status
kubectl get pods -n production
```

### Manuten√ß√£o da Base de Dados

**1. Backup Autom√°tico**
```bash
#!/bin/bash
# scripts/backup_db.sh
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="harvey_backup_${DATE}.sql"

pg_dump -h $DB_HOST -U $DB_USER $DB_NAME > /backups/$BACKUP_FILE
gzip /backups/$BACKUP_FILE

# Upload para S3
aws s3 cp /backups/${BACKUP_FILE}.gz s3://harvey-backups/database/
```

**2. Limpeza de Dados Antigos**
```sql
-- Limpar dados de auditoria > 7 anos
DELETE FROM run_audit 
WHERE created_at < NOW() - INTERVAL '7 years';

-- Limpar dados tempor√°rios > 30 dias
DELETE FROM temp_data 
WHERE created_at < NOW() - INTERVAL '30 days';

-- Reindexar tabelas
REINDEX TABLE run_audit;
REINDEX TABLE feedback_events;
```

### Rota√ß√£o de Logs

**1. Configura√ß√£o do Logrotate**
```bash
# /etc/logrotate.d/harvey-backend
/var/log/harvey-backend/*.log {
    daily
    rotate 30
    compress
    delaycompress
    missingok
    notifempty
    create 0644 harvey harvey
    postrotate
        systemctl reload harvey-backend
    endscript
}
```

---

## üöÄ PROCEDIMENTOS DE SCALE

### Scale Horizontal

**1. Aumentar R√©plicas**
```bash
# Via kubectl
kubectl scale deployment harvey-backend --replicas=5 -n production

# Via Helm
helm upgrade harvey-production ./helm/harvey \
  --set replicaCount=5 \
  --namespace production
```

**2. Configurar Autoscaling**
```yaml
# HPA Configuration
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: harvey-backend-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: harvey-backend
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### Scale Vertical

**1. Aumentar Recursos**
```bash
# Via Helm
helm upgrade harvey-production ./helm/harvey \
  --set resources.requests.cpu=1000m \
  --set resources.requests.memory=2Gi \
  --set resources.limits.cpu=2000m \
  --set resources.limits.memory=4Gi \
  --namespace production
```

---

## üìä DASHBOARDS E RELAT√ìRIOS

### Dashboard Principal (Grafana)

**1. M√©tricas de Sistema**
- CPU Usage por pod
- Memory Usage por pod
- Network I/O
- Disk I/O

**2. M√©tricas de Aplica√ß√£o**
- Requests per second
- Response time percentiles
- Error rates por endpoint
- Active connections

**3. M√©tricas de Neg√≥cio**
- Documentos gerados por hora
- Taxa de sucesso
- Feedback scores
- Usu√°rios ativos

### Relat√≥rios Autom√°ticos

**1. Relat√≥rio Di√°rio**
```python
# scripts/daily_report.py
import asyncio
from datetime import datetime, timedelta
from app.core.database import get_db

async def generate_daily_report():
    db = await get_db()
    yesterday = datetime.now() - timedelta(days=1)
    
    # M√©tricas do dia anterior
    stats = await db.fetch_one("""
        SELECT 
            COUNT(*) as total_runs,
            AVG(execution_time_ms) as avg_execution_time,
            COUNT(CASE WHEN pii_report->>'pii_detected' = 'true' THEN 1 END) as pii_detections,
            AVG(CASE WHEN rating > 0 THEN rating END) as avg_rating
        FROM run_audit ra
        LEFT JOIN feedback_events fe ON ra.run_id = fe.run_id
        WHERE ra.created_at >= %s
    """, yesterday)
    
    # Enviar relat√≥rio por email/Slack
    send_report(stats)
```

---

## üîí SEGURAN√áA E COMPLIANCE

### Verifica√ß√£o de Seguran√ßa

**1. Scan de Vulnerabilidades**
```bash
# Scan da imagem Docker
trivy image ghcr.io/seu-usuario/harvey-backend:latest

# Scan do cluster
kube-bench run --check 4.2.1,4.2.2
```

**2. Verifica√ß√£o de Pol√≠ticas**
```bash
# Verificar pol√≠ticas de seguran√ßa
kubectl get networkpolicies -n production
kubectl get podsecuritypolicies
```

### Auditoria de Compliance

**1. Relat√≥rio de Conformidade LGPD**
```sql
-- Verificar processamento de PII
SELECT 
    DATE(created_at) as date,
    COUNT(*) as total_runs,
    COUNT(CASE WHEN pii_report->>'pii_detected' = 'true' THEN 1 END) as pii_runs,
    COUNT(CASE WHEN pii_report->>'pii_redacted' = 'true' THEN 1 END) as pii_redacted
FROM run_audit 
WHERE created_at >= NOW() - INTERVAL '30 days'
GROUP BY DATE(created_at)
ORDER BY date DESC;
```

**2. Verifica√ß√£o de Integridade**
```python
# scripts/integrity_check.py
import hashlib
from app.core.database import get_db

async def verify_integrity():
    db = await get_db()
    
    # Verificar hashes
    records = await db.fetch_all("""
        SELECT run_id, input_text, input_hash, output_text, output_hash
        FROM run_audit
        WHERE created_at >= NOW() - INTERVAL '1 day'
    """)
    
    for record in records:
        # Verificar hash do input
        calculated_input_hash = hashlib.sha256(record.input_text.encode()).hexdigest()
        if calculated_input_hash != record.input_hash:
            print(f"INTEGRITY VIOLATION: Run {record.run_id} - Input hash mismatch")
            
        # Verificar hash do output
        calculated_output_hash = hashlib.sha256(record.output_text.encode()).hexdigest()
        if calculated_output_hash != record.output_hash:
            print(f"INTEGRITY VIOLATION: Run {record.run_id} - Output hash mismatch")
```

---

## üìû CONTATOS DE EMERG√äNCIA

### Equipe de Plant√£o

**Desenvolvedor Principal**
- Nome: [Seu Nome]
- Email: dev@harvey.ai
- Telefone: +55 11 99999-9999
- Slack: @dev-principal

**DevOps/SRE**
- Nome: [Nome DevOps]
- Email: devops@harvey.ai
- Telefone: +55 11 88888-8888
- Slack: @devops-lead

**Compliance Officer**
- Nome: [Nome Compliance]
- Email: compliance@harvey.ai
- Telefone: +55 11 77777-7777
- Slack: @compliance-officer

### Fornecedores Cr√≠ticos

**OpenAI**
- Status: https://status.openai.com/
- Suporte: platform.openai.com/support

**Anthropic**
- Status: https://status.anthropic.com/
- Suporte: support@anthropic.com

**AWS/Cloud Provider**
- Status: https://status.aws.amazon.com/
- Suporte: AWS Support Console

---

## üéØ PROCEDIMENTOS DE TESTE

### Testes de Carga

**1. Teste com Artillery**
```yaml
# load-test.yml
config:
  target: 'https://harvey-api.exemplo.com'
  phases:
    - duration: 60
      arrivalRate: 10
    - duration: 120
      arrivalRate: 20
    - duration: 60
      arrivalRate: 50

scenarios:
  - name: "Generate Document"
    weight: 70
    flow:
      - post:
          url: "/api/v1/generate"
          json:
            tipo_documento: "peticao_inicial"
            contexto: "A√ß√£o de cobran√ßa"
            partes: {...}
            
  - name: "Health Check"
    weight: 30
    flow:
      - get:
          url: "/health"
```

**2. Executar Teste**
```bash
# Instalar Artillery
npm install -g artillery

# Executar teste
artillery run load-test.yml
```

### Testes de Disaster Recovery

**1. Simula√ß√£o de Falha de Pod**
```bash
# Deletar pod aleat√≥rio
kubectl delete pod -l app=harvey-backend -n production --force

# Verificar recupera√ß√£o
kubectl get pods -n production -w
```

**2. Simula√ß√£o de Falha de Banco**
```bash
# Parar banco temporariamente
kubectl scale deployment postgres --replicas=0 -n production

# Verificar comportamento da API
curl -f https://harvey-api.exemplo.com/health

# Restaurar banco
kubectl scale deployment postgres --replicas=1 -n production
```

---

## üìù CHANGELOG E VERSIONING

### Formato de Versionamento

Seguimos **Semantic Versioning** (SemVer):
- **MAJOR**: Mudan√ßas incompat√≠veis na API
- **MINOR**: Funcionalidades adicionadas de forma compat√≠vel
- **PATCH**: Corre√ß√µes de bugs compat√≠veis

### Exemplo de Changelog

```markdown
# Changelog

## [1.2.3] - 2024-01-15

### Added
- Nova funcionalidade de feedback estruturado
- Suporte para detec√ß√£o de PII em documentos
- Auditoria forense com hashes SHA-256

### Changed
- Melhorada performance do RAG em 30%
- Atualizado LangGraph para vers√£o 0.2.0

### Fixed
- Corrigido bug na gera√ß√£o de contratos
- Resolvido problema de memory leak

### Security
- Implementado mascaramento de dados sens√≠veis
- Adicionadas pol√≠ticas de seguran√ßa por tenant
```

---

*Este runbook deve ser atualizado regularmente conforme o sistema evolui. √öltima atualiza√ß√£o: Janeiro 2025*
