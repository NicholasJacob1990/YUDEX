"""
Harvey Backend - FastAPI Main Application com LangGraph
Sistema RAG jur√≠dico com orquestra√ß√£o din√¢mica de agentes
"""

from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
from langgraph.graph import StateGraph, END, START
from langgraph.checkpoint.memory import MemorySaver
import uvicorn
from typing import Dict, Any
import uuid

# Importa√ß√µes locais
from app.orch.state import GraphState
from app.orch.agents import analyzer_node, drafter_node, critic_node, formatter_node, researcher_node
from app.orch.supervisor import supervisor_router, get_execution_summary
from app.security.auth import get_api_identity
from app.api.v1 import feedback as feedback_router
from app.api.centroids import router as centroids_router
from app.core.audit import build_and_save_audit_record

# Vari√°veis globais
workflow = None
graph = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Lifecycle da aplica√ß√£o"""
    global workflow, graph
    
    # Startup
    print("üöÄ Iniciando Harvey Backend com LangGraph...")
    
    # --- Constru√ß√£o do Grafo LangGraph ---
    workflow = StateGraph(GraphState)
    
    # Adicionar os n√≥s (agentes)
    workflow.add_node("analyzer", analyzer_node)
    workflow.add_node("researcher", researcher_node)
    workflow.add_node("drafter", drafter_node)
    workflow.add_node("critic", critic_node)
    workflow.add_node("formatter", formatter_node)
    
    # O ponto de entrada usa o supervisor para decidir o primeiro n√≥
    workflow.add_conditional_edges(
        START,
        supervisor_router,
        {
            "analyzer": "analyzer",
            "researcher": "researcher",
            "drafter": "drafter",
            "critic": "critic",
            "formatter": "formatter",
            "end": END
        }
    )
    
    # Ap√≥s cada n√≥, volta ao supervisor para decidir o pr√≥ximo passo
    workflow.add_conditional_edges(
        "analyzer",
        supervisor_router,
        {
            "analyzer": "analyzer",
            "researcher": "researcher",
            "drafter": "drafter",
            "critic": "critic",
            "formatter": "formatter",
            "end": END
        }
    )
    
    workflow.add_conditional_edges(
        "researcher",
        supervisor_router,
        {
            "analyzer": "analyzer",
            "researcher": "researcher",
            "drafter": "drafter",
            "critic": "critic",
            "formatter": "formatter",
            "end": END
        }
    )
    
    workflow.add_conditional_edges(
        "drafter",
        supervisor_router,
        {
            "analyzer": "analyzer",
            "researcher": "researcher",
            "drafter": "drafter",
            "critic": "critic",
            "formatter": "formatter",
            "end": END
        }
    )
    
    workflow.add_conditional_edges(
        "critic",
        supervisor_router,
        {
            "analyzer": "analyzer",
            "researcher": "researcher",
            "drafter": "drafter",
            "critic": "critic",
            "formatter": "formatter",
            "end": END
        }
    )
    
    workflow.add_conditional_edges(
        "formatter",
        supervisor_router,
        {
            "analyzer": "analyzer",
            "researcher": "researcher",
            "drafter": "drafter",
            "critic": "critic",
            "formatter": "formatter",
            "end": END
        }
    )
    
    # Compilar o grafo com checkpointer de mem√≥ria
    memory_saver = MemorySaver()
    graph = workflow.compile(checkpointer=memory_saver)
    
    print("‚úÖ Harvey Backend com LangGraph inicializado!")
    
    yield
    
    # Shutdown
    print("üõë Encerrando Harvey Backend...")

# Cria aplica√ß√£o FastAPI
app = FastAPI(
    title="Harvey Backend",
    description="Sistema RAG jur√≠dico com orquestra√ß√£o din√¢mica usando LangGraph",
    version="1.0.0",
    lifespan=lifespan
)

# Configura√ß√£o CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configurar adequadamente em produ√ß√£o
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Inclus√£o dos routers da API
app.include_router(feedback_router.router, prefix="/api/v1")

# Rotas de status
@app.get("/")
async def root():
    """Rota raiz - status da aplica√ß√£o"""
    return {
        "service": "Harvey Backend",
        "version": "1.0.0",
        "status": "running",
        "description": "Sistema RAG jur√≠dico com orquestra√ß√£o din√¢mica (LangGraph)",
        "graph_compiled": graph is not None
    }

@app.get("/health")
async def health_check():
    """Health check da aplica√ß√£o"""
    return {
        "status": "healthy",
        "graph_ready": graph is not None,
        "workflow_nodes": len(workflow.nodes) if workflow else 0
    }

# Rota principal - execu√ß√£o do grafo din√¢mico
@app.post("/v1/generate/dynamic")
async def generate_document_dynamic(
    payload: Dict[str, Any], 
    identity: Dict[str, Any] = Depends(get_api_identity)
):
    """
    Endpoint que executa o pipeline din√¢mico usando LangGraph.
    
    Exemplo de payload:
    {
        "query": "Redija um parecer sobre limites de contratos administrativos",
        "task": "draft",
        "doc_type": "parecer",
        "docs": [{"content": "...", "source": "Lei 8.666/93"}],
        "config": {"complexity": "medium"}
    }
    """
    
    if not graph:
        raise HTTPException(status_code=500, detail="Grafo n√£o inicializado")
    
    try:
        # Gerar ID √∫nico para a execu√ß√£o
        run_id = payload.get("run_id", str(uuid.uuid4()))
        thread_config = {"configurable": {"thread_id": run_id}}
        
        # Criar estado inicial
        initial_state = GraphState(
            run_id=run_id,
            tenant_id=identity["tenant_id"],
            initial_query=payload.get("query", ""),
            task=payload.get("task", "draft"),
            doc_type=payload.get("doc_type", "documento"),
            rag_docs=payload.get("docs", []),
            config=payload.get("config", {}),
            supervisor_notes=[],
            metrics={}
        )
        
        # Executar o grafo
        final_state = None
        execution_log = []
        
        async for event in graph.astream(initial_state, config=thread_config):
            # Streaming de eventos para monitoramento
            for node_name, output in event.items():
                print(f"--- N√≥ executado: {node_name} ---")
                print(f"Estado parcial: {list(output.keys())}")
                
                execution_log.append({
                    "node": node_name,
                    "output_keys": list(output.keys()),
                    "supervisor_notes": output.get("supervisor_notes", [])
                })
                
                final_state = output
                
        if not final_state:
            raise HTTPException(status_code=500, detail="Falha ao processar - estado final vazio")
        
        # Gerar resumo de execu√ß√£o
        execution_summary = get_execution_summary(final_state)
        
        return {
            "success": True,
            "run_id": run_id,
            "final_state": final_state,
            "execution_summary": execution_summary,
            "execution_log": execution_log,
            "final_document": final_state.get("final_text", final_state.get("critic_latest_markdown", final_state.get("draft_markdown")))
        }
        
    except Exception as e:
        print(f"Erro na execu√ß√£o do grafo: {e}")
        raise HTTPException(status_code=500, detail=f"Erro na execu√ß√£o: {str(e)}")

# Rota para execu√ß√£o com streaming
@app.post("/v1/generate/stream")
async def generate_document_stream(
    payload: Dict[str, Any],
    identity: Dict[str, Any] = Depends(get_api_identity)
):
    """
    Endpoint para execu√ß√£o com streaming de eventos.
    Retorna os eventos conforme s√£o processados.
    """
    
    if not graph:
        raise HTTPException(status_code=500, detail="Grafo n√£o inicializado")
    
    # TODO: Implementar streaming real com Server-Sent Events
    # Por enquanto, retorna placeholder
    return {
        "message": "Streaming ser√° implementado em vers√£o futura",
        "alternative": "Use /v1/generate/dynamic para execu√ß√£o completa"
    }

# Rotas de debug/desenvolvimento
@app.get("/debug/graph")
async def debug_graph():
    """Informa√ß√µes sobre o grafo"""
    if not graph or not workflow:
        return {"error": "Grafo n√£o inicializado"}
    
    return {
        "nodes": list(workflow.nodes.keys()),
        "edges": len(workflow.edges),
        "compiled": graph is not None,
        "state_schema": "GraphState (LangGraph TypedDict)"
    }

# Incluir routers
app.include_router(feedback_router.router)
app.include_router(centroids_router)

@app.get("/debug/supervisor")
async def debug_supervisor():
    """Testa o supervisor com estado mockado"""
    
    # Estado de teste
    test_state = GraphState(
        run_id="test_run",
        tenant_id="test_tenant",
        initial_query="Teste do supervisor",
        task="draft",
        doc_type="parecer",
        rag_docs=[],
        config={},
        supervisor_notes=[],
        metrics={}
    )
    
    # Testa roteamento
    next_node = supervisor_router(test_state)
    
    return {
        "test_state": dict(test_state),
        "supervisor_decision": next_node,
        "execution_summary": get_execution_summary(test_state)
    }

if __name__ == "__main__":
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
